{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a020c045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "from tqdm.notebook import tqdm as tn\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "russian_stopwords = nltk.corpus.stopwords.words('russian')\n",
    "english_stopwords = nltk.corpus.stopwords.words('english')\n",
    "word_tokenizer = nltk.WordPunctTokenizer()\n",
    "\n",
    "\n",
    "data_path = r\"C:\\Users\\User\\Desktop\\Study\\2_sem\\blek\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7e90335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://spbu.ru/</td>\n",
       "      <td>2023-04-14T00:56:50.6368499Z</td>\n",
       "      <td>Главная | Санкт-Петербургский государствен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://cabinet.spbu.ru/Account/LogOn/</td>\n",
       "      <td>2023-04-14T00:57:02.6226399Z</td>\n",
       "      <td>Вход      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://bb.spbu.ru/</td>\n",
       "      <td>2023-04-14T00:57:02.6225294Z</td>\n",
       "      <td>Blackboard Learn                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://events.spbu.ru/</td>\n",
       "      <td>2023-04-14T00:57:03.8827793Z</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://cabinet.spbu.ru/Account/Register/</td>\n",
       "      <td>2023-04-14T00:57:06.6414451Z</td>\n",
       "      <td>Регистраци...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0                             1  \\\n",
       "0                           https://spbu.ru/  2023-04-14T00:56:50.6368499Z   \n",
       "1     https://cabinet.spbu.ru/Account/LogOn/  2023-04-14T00:57:02.6226399Z   \n",
       "2                         http://bb.spbu.ru/  2023-04-14T00:57:02.6225294Z   \n",
       "3                    https://events.spbu.ru/  2023-04-14T00:57:03.8827793Z   \n",
       "4  https://cabinet.spbu.ru/Account/Register/  2023-04-14T00:57:06.6414451Z   \n",
       "\n",
       "                                                   2  \n",
       "0      Главная | Санкт-Петербургский государствен...  \n",
       "1                                      Вход      ...  \n",
       "2    Blackboard Learn                            ...  \n",
       "3                                                ...  \n",
       "4                                      Регистраци...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_spbu = pd.read_csv(f\"{data_path}/spbu_content.csv\", header = None)\n",
    "data_spbu.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "959ac17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://msu.ru/</td>\n",
       "      <td>2023-04-15T16:29:55.1662631Z</td>\n",
       "      <td>\\t\\tМосковский государственный университет име...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://msu.ru/news/rss/</td>\n",
       "      <td>2023-04-15T16:30:13.1464229Z</td>\n",
       "      <td>\\tНовости МГУhttp://www.msu.ruSat, 15 Apr 2023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://270.msu.ru/</td>\n",
       "      <td>2023-04-15T16:30:09.1446391Z</td>\n",
       "      <td>270 лет Московскому университету     Указ Пре...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://conf.msu.ru/rus/event/8147/</td>\n",
       "      <td>2023-04-15T16:30:09.1695835Z</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://nosh.msu.ru/</td>\n",
       "      <td>2023-04-15T16:30:11.2455821Z</td>\n",
       "      <td>Научно-образовательные школы Московского унив...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0                             1  \\\n",
       "0                      https://msu.ru/  2023-04-15T16:29:55.1662631Z   \n",
       "1             https://msu.ru/news/rss/  2023-04-15T16:30:13.1464229Z   \n",
       "2                   http://270.msu.ru/  2023-04-15T16:30:09.1446391Z   \n",
       "3  https://conf.msu.ru/rus/event/8147/  2023-04-15T16:30:09.1695835Z   \n",
       "4                  http://nosh.msu.ru/  2023-04-15T16:30:11.2455821Z   \n",
       "\n",
       "                                                   2  \n",
       "0  \\t\\tМосковский государственный университет име...  \n",
       "1  \\tНовости МГУhttp://www.msu.ruSat, 15 Apr 2023...  \n",
       "2   270 лет Московскому университету     Указ Пре...  \n",
       "3                                                ...  \n",
       "4   Научно-образовательные школы Московского унив...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_msu = pd.read_csv(f\"{data_path}/msu_content.csv\", header = None)\n",
    "data_msu.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd7d55a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_cyrillic(text: str) -> bool: # проверяем, слово содержит русские буквы или нет \n",
    "    return bool(re.search('[а-яА-Я]', text))\n",
    "\n",
    "def has_english(text: str) -> bool: # проверяем, слово содержит английские буквы или нет \n",
    "    return bool(re.search('[a-zA-z]', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcbeda9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spbu = data_spbu[~data_spbu[0].str.endswith('.pdf/')] # удаляем строки из датафрейма, которые пдфки\n",
    "data_spbu = data_spbu.reset_index(drop=True) # сбрасываем индексы чтобы не возникало ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e109e0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://spbu.ru/</td>\n",
       "      <td>2023-04-14T00:56:50.6368499Z</td>\n",
       "      <td>Главная | Санкт-Петербургский государствен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://cabinet.spbu.ru/Account/LogOn/</td>\n",
       "      <td>2023-04-14T00:57:02.6226399Z</td>\n",
       "      <td>Вход      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://bb.spbu.ru/</td>\n",
       "      <td>2023-04-14T00:57:02.6225294Z</td>\n",
       "      <td>Blackboard Learn                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://events.spbu.ru/</td>\n",
       "      <td>2023-04-14T00:57:03.8827793Z</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://cabinet.spbu.ru/Account/Register/</td>\n",
       "      <td>2023-04-14T00:57:06.6414451Z</td>\n",
       "      <td>Регистраци...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30428</th>\n",
       "      <td>http://publishing.spbu.ru/catalog/tematicheski...</td>\n",
       "      <td>2023-04-15T14:12:41.5942241Z</td>\n",
       "      <td>\\tКнига Арт-терапия в  профилактической и  леч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30429</th>\n",
       "      <td>http://publishing.spbu.ru/catalog/periodichesk...</td>\n",
       "      <td>2023-04-15T14:13:48.1417110Z</td>\n",
       "      <td>\\tЖурнал Новейшая история России - Издательств...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30430</th>\n",
       "      <td>http://publishing.spbu.ru/catalog/tematicheski...</td>\n",
       "      <td>2023-04-15T14:13:54.6711058Z</td>\n",
       "      <td>\\tКнига Мышление и его расстройства при психич...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30431</th>\n",
       "      <td>http://publishing.spbu.ru/catalog/periodichesk...</td>\n",
       "      <td>2023-04-15T14:14:22.0093077Z</td>\n",
       "      <td>\\tВестник СПбГУ. Международные отношения - Изд...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30432</th>\n",
       "      <td>https://spbu.ru/universitet/podrazdeleniya-i-r...</td>\n",
       "      <td>2023-04-15T14:14:37.2722973Z</td>\n",
       "      <td>Совет образовательной программы «Процессы ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30433 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  \\\n",
       "0                                       https://spbu.ru/   \n",
       "1                 https://cabinet.spbu.ru/Account/LogOn/   \n",
       "2                                     http://bb.spbu.ru/   \n",
       "3                                https://events.spbu.ru/   \n",
       "4              https://cabinet.spbu.ru/Account/Register/   \n",
       "...                                                  ...   \n",
       "30428  http://publishing.spbu.ru/catalog/tematicheski...   \n",
       "30429  http://publishing.spbu.ru/catalog/periodichesk...   \n",
       "30430  http://publishing.spbu.ru/catalog/tematicheski...   \n",
       "30431  http://publishing.spbu.ru/catalog/periodichesk...   \n",
       "30432  https://spbu.ru/universitet/podrazdeleniya-i-r...   \n",
       "\n",
       "                                  1  \\\n",
       "0      2023-04-14T00:56:50.6368499Z   \n",
       "1      2023-04-14T00:57:02.6226399Z   \n",
       "2      2023-04-14T00:57:02.6225294Z   \n",
       "3      2023-04-14T00:57:03.8827793Z   \n",
       "4      2023-04-14T00:57:06.6414451Z   \n",
       "...                             ...   \n",
       "30428  2023-04-15T14:12:41.5942241Z   \n",
       "30429  2023-04-15T14:13:48.1417110Z   \n",
       "30430  2023-04-15T14:13:54.6711058Z   \n",
       "30431  2023-04-15T14:14:22.0093077Z   \n",
       "30432  2023-04-15T14:14:37.2722973Z   \n",
       "\n",
       "                                                       2  \n",
       "0          Главная | Санкт-Петербургский государствен...  \n",
       "1                                          Вход      ...  \n",
       "2        Blackboard Learn                            ...  \n",
       "3                                                    ...  \n",
       "4                                          Регистраци...  \n",
       "...                                                  ...  \n",
       "30428  \\tКнига Арт-терапия в  профилактической и  леч...  \n",
       "30429  \\tЖурнал Новейшая история России - Издательств...  \n",
       "30430  \\tКнига Мышление и его расстройства при психич...  \n",
       "30431  \\tВестник СПбГУ. Международные отношения - Изд...  \n",
       "30432      Совет образовательной программы «Процессы ...  \n",
       "\n",
       "[30433 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_spbu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e098d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def lemmatization(data_spbu):\n",
    "    df = data_spbu.copy()\n",
    "    list_errors = []\n",
    "    for i in range(df.shape[0]):\n",
    "        sub_string = data_spbu.iloc[i, 2]\n",
    "        if type(sub_string) is str:\n",
    "            word_list = nltk.word_tokenize(sub_string.lower()) # делаем маленькие буквы, разбиваем текст на токены (из 3-го столбика по каждой строке)\n",
    "\n",
    "            word_list = [word for word in word_list if  (\n",
    "                word not in russian_stopwords and\n",
    "                word not in english_stopwords and\n",
    "                not word.isnumeric() and \n",
    "                (has_cyrillic(word) or has_english(word))\n",
    "                )\n",
    "            ] # удаляем слова, которые в англ и русс стоп-словах или если они числовые (строчки)\n",
    "\n",
    "            try:\n",
    "                word_list = [morph.parse(j)[0].normal_form for j in word_list] # нормальная форма токена\n",
    "                df.iloc[i, 2] = ' '.join(word_list) # заменяем 3 столбик на лемматизированный текст\n",
    "            except:\n",
    "                list_errors.append(i) # в лист ошибок добавляем номер строки, в которой ошибка \n",
    "    \n",
    "    return df, list_errors\n",
    "\n",
    "df, list_errors = lemmatization(data_spbu) # переменные из ретерна, которые возвращает функция "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b924610d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[426, 3306, 4132] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop_errors\u001b[39m(df, list_errors):\n\u001b[0;32m      2\u001b[0m     \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39mdrop(index\u001b[39m=\u001b[39mlist_errors) \u001b[39m# удаляем все строки с ошибками\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df \u001b[39m=\u001b[39m drop_errors(df\u001b[39m=\u001b[39;49mdf, list_errors\u001b[39m=\u001b[39;49mlist_errors)\n",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m, in \u001b[0;36mdrop_errors\u001b[1;34m(df, list_errors)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop_errors\u001b[39m(df, list_errors):\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39;49mdrop(index\u001b[39m=\u001b[39;49mlist_errors)\n",
      "File \u001b[1;32mc:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:5396\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5248\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   5249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5250\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5257\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5258\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5259\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5260\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5261\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5394\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5395\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5396\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5397\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5398\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5399\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5400\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5401\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5402\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5403\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5404\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Дмитрий\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6977\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6975\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6976\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6977\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6978\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6979\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[426, 3306, 4132] not found in axis'"
     ]
    }
   ],
   "source": [
    "def drop_errors(df, list_errors):\n",
    "    return df.drop(index=list_errors) # удаляем все строки с ошибками\n",
    "\n",
    "df = drop_errors(df=df, list_errors=list_errors)\n",
    "\n",
    "df = df.reset_index(drop=True) # сбрасываем индексы чтобы не возникало ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa3f4ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{data_path}\\df_spbu.csv\") # сохраняем обработанный датафрейм в новый csv для последующего использования (токенизированный и почищенный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd0346f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def create_dict(df):\\n    my_dict = {}\\n\\n    for idx in range(df.shape[0]):  # цикл, который обрабатывает строки\\n        if isinstance(df.iloc[idx][2], str):\\n            tokens_list = list()\\n            tokens_list = df.iloc[idx][2].split() # если строка не встречается в листе ошибок (то что не получилось обработать на лемматизации)\\n            for token in tokens_list: # тут цикл, который обрабатывает токены (он смотрит, есть ли какая-то запись в словаре, соответствующая конкретному слову)\\n                if token in my_dict: # если ключ уже есть, то добавляем в список ссылку\\n                    my_dict[token].append(df.iloc[idx][0])\\n                else:  \\n                    my_dict[token] = [df.iloc[idx][0]] # пыталась тут добавить ключ и значение (то есть ссылку), если их нет в словаре \\n\\n    return my_dict\\n\\nmy_dict = create_dict(df)   '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{data_path}/df_spbu.csv', index_col=0,)\n",
    "\n",
    "df.reset_index(inplace= True) #добавляем столбик индексов --> [0]\n",
    "\n",
    "def create_dict(df):\n",
    "    my_dict = {}\n",
    "\n",
    "    for idx in range(df.shape[0]):  # цикл, который обрабатывает строки\n",
    "        if isinstance(df.iloc[idx][3], str):\n",
    "            tokens_list = list()\n",
    "            tokens_list = df.iloc[idx][3].split() # если строка не встречается в листе ошибок (то что не получилось обработать на лемматизации)\n",
    "            for token in tokens_list: # тут цикл, который обрабатывает токены (он смотрит, есть ли какая-то запись в словаре, соответствующая конкретному слову)\n",
    "                if token in my_dict: # если ключ уже есть, то добавляем в список ссылку\n",
    "                    my_dict[token].append(df.iloc[idx][0])\n",
    "                else:  \n",
    "                    my_dict[token] = [df.iloc[idx][0]] # пыталась тут добавить ключ и значение (то есть ссылку), если их нет в словаре \n",
    "\n",
    "    return my_dict\n",
    "\n",
    "my_dict = create_dict(df)         \n",
    "            # если запись в словаре есть - идем дальше, если записи в словаре нет - добавляем эту строку в лист для конкретного ключа\n",
    "            # ну либо (если первый раз встречается) создаем лист, в который записывается значение строки для ключа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b84eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_path}/result.json', 'w') as fp: # сохраняем словарь в json\n",
    "    json.dump(my_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f97ee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_path}/result.json', 'r') as fp: #считываем словарь из json\n",
    "    data = json.loads(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a52973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
