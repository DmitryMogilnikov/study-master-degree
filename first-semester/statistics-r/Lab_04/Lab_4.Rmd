---
title: "Лабораторная работа 4"
author: "Могильников Дмитрий"
date: "2022-11-30"
output: html_document
---

## Задание 1
### Используйте датасет из Лабораторной работы 3.

Загрузим датасет и выведем его через head()
```{r set-options, cache=FALSE}
options(width = 100)
library("MASS")
boston_df <- Boston

head(boston_df)
```
Таблица с описанием для каждой переменной в проедставленном датасете:

|Feature Variable|Description|
|:-|:-------|
|CRIM|per capita crime rate by town.|
|ZN|proportion of residential land zoned for lots over 25,000 sq.ft.|
|INDUS|proportion of non-retail business acres per town.|
|CHAS|Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).|
|NOX|nitrogen oxides concentration (parts per 10 million).|
|RM|average number of rooms per dwelling.|
|AGE|proportion of owner-occupied units built prior to 1940.|
|DIS|weighted mean of distances to five Boston employment centres.|
|RAD|index of accessibility to radial highways.|
|TAX|full-value property-tax rate per \$10,000.|
|PTRATIO|pupil-teacher ratio by town.|
|BLACK|1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.|
|LSTAT|lower status of the population (percent).|
|MEDV|median value of owner-occupied homes in \$1000s.|

## Задание 2
### Повторно выведите корреляционную матрицу по всем переменным.
```{r, out.width="100%"}
attach(boston_df)
library(ggplot2)
library(corrplot)

corrplot(cor(boston_df),
         method = "color",
         addCoef.col = 1,
         type="upper",
         number.cex = 0.6)
```

## Задание 3
### Выберите зависимую и независимую переменные (y и x), постройте парную линейную регрессию, выведите график наблюдаемых значений и полученной прямой.

#### Коэффициент корреляции варьируется от -1 до 1. Если значение близко к 1, это означает, что между двумя переменными существует сильная положительная корреляция. Когда он близок к -1, переменные имеют сильную отрицательную корреляцию.
#### В качестве зависимой переменной выберем MEDV(медианная стоимость домов), чтобы получить соответствие в модели линейной регрессии, мы выбираем те функции, которые имеют высокую корреляцию с нашей целевой переменной MEDV. Основываясь на приведенных выше наблюдениях, в качестве независимой переменной выберем переменные RM и LSTAT, которые имеют сильную положительную и отрицательную корелляции соответственно. 

```{r, out.width="100%"}
fit_rm <-lm(medv~rm)
summary(fit_rm)

ggplot(data = boston_df, aes(x = rm, y = medv)) +
  geom_point(color = "orange") +
  labs(title = "RM",
       x = "RM",
       y = "MEDV") +
  geom_smooth(method = lm, se = FALSE, color = "red")

fit_lstat <-lm(medv~lstat)
summary(fit_lstat)

ggplot(data = boston_df, aes(x = lstat, y = medv)) +
  geom_point(color = "orange") +
  labs(title = "LSTAT",
       x = "LSTAT",
       y = "MEDV") +
  geom_smooth(method = lm, se = FALSE, color = "red")
```

## Задание 4
### Сделайте выводы по полученным оценкам.

#### Полученные линейные зависимости описываются следующими уравнениями: 
#### 1. MEDV = -34.671 + 9.102 * RM
#### 2. MEDV = 34.55384 - -0.95005 * LSTAT
#### Для обеих зависимостей мы видим что p-value лежит в области доверительного интервала (< 0,05), значит можем считать, что модель в целом является статистически значимой. Multiple R-squared:  0.4835 для переменной RM, Multiple R-squared:  0.5441 для переменной LSTAT, возможно такие значения обусловлены тем, что точки распределены в достаточно большом диапазоне по целевой переменной.
#### Цены растут по мере увеличения среднего количества комнат линейно.
#### Цены, как правило, снижаются с увеличением LSTAT (более низкий статус населения (в процентах)). Хотя, похоже, что он не следует точно линейной зависимости в начале.

## Задание 5 
### Выберите зависимую и несколько независимых переменных (минимум две), постройте множественную линейную регрессию.

#### Переменные RM и LSTAT имеют коэффициент корелляции -0,61 и могут быть зависимыми, поэтому для построения множественной линейной регрессии будем использовать переменные RM и PTRATIO(соотношение учеников и учителей по городам.) Коэффициент корреляции между этими двумя переменными -0,36
```{r, out.width="100%"}
library(GGally)
ggpairs(boston_df[, c("medv", "rm", "ptratio")]) 
fit_rm_ptratio <-lm(formula = medv ~ rm + ptratio)
summary(fit_rm_ptratio)
```

#### Построим множественную регрессию для переменных RM и LSTAT, а также проверим значения R-квадрат, построив Ridge-регрессию(используется когда в данных может присутствовать мультиколлинеарность) 
```{r, out.width="100%"}
# Классическая множественная линейная регрессия
fit_rm_lstat <-lm(formula = medv ~ rm + lstat)
summary(fit_rm_lstat)

#Построение Ridge-регрессии
library(glmnet)
y = medv
x = data.matrix(boston_df[, c("rm", "lstat")])
model <- glmnet(x, y, alpha = 0)

#Проведем кросс-валидацию и получим лучший параметр лямбда, дающий наименьшую среднеквадратичную ошибку
cv_model <- cv.glmnet(x, y, alpha = 0)
best_lambda <- cv_model$lambda.min
best_lambda

#Рассчитаем R-квадрат полученной модели
y_predicted <- predict (model, s = best_lambda, newx = x)
sst <- sum ((y - mean (y))^2)
sse <- sum ((y_predicted - y)^2)
rsq <- 1 - sse/sst
rsq
```

## Задание 6 
### Сделайте выводы по полученным оценкам.
#### Для зависимой переменной MEDV и независимых переменных RM и PTRATIO множественная линейная регрессия является статистически значимой, p-value < 0,05
#### Для зависимой переменной MEDV и независимых переменных RM и LSTAT множественная линейная регрессия также является статистически значимой, p-value < 0,05. R-квадрат полученный в ходе построения множественной линейной регрессии совпадает со значением полученным из ridge-регрессии, это говорит о том, что переменные RM и LSTAT независимы.