{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Bron–Kerbosch algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bron_kerbosch(R, P, X, graph, cliques):\n",
    "    if not P and not X:\n",
    "        cliques.append(R)\n",
    "    for v in P.copy():\n",
    "        bron_kerbosch(\n",
    "            R.union([v]), \n",
    "            P.intersection(graph[v]), \n",
    "            X.intersection(graph[v]), \n",
    "            graph, \n",
    "            cliques,\n",
    "        )\n",
    "        P.remove(v)\n",
    "        X.add(v)\n",
    "\n",
    "def find_all_cliques(graph):\n",
    "    P = set(graph.keys())  # содержит все вершины графа\n",
    "    R = set() # Содержит текущую клику\n",
    "    X = set() # Содержит вершины, которые уже рассмотрены\n",
    "    cliques = [] # Список максимальных клик\n",
    "    bron_kerbosch(R, P, X, graph, cliques) \n",
    "    return cliques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{1, 2, 5}, {2, 3}, {3, 4}, {4, 5}, {4, 6}]\n"
     ]
    }
   ],
   "source": [
    "graph = {\n",
    "    1: [2, 5],\n",
    "    2: [1, 3, 5],\n",
    "    3: [2, 4],\n",
    "    4: [3, 5, 6],\n",
    "    5: [1, 2, 4],\n",
    "    6: [4],\n",
    "}\n",
    "\n",
    "cliques = find_all_cliques(graph)\n",
    "print(cliques)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth # максимальная глубина дерева\n",
    "        self.min_samples_split = min_samples_split # минимальное количество объектов для разделения в узле\n",
    "        self.split_feature = None\n",
    "        self.split_value = None\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        self.label = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Если максимальная глубина не была указана, она устанавливается равной числу признаков в данных X.\n",
    "        if self.max_depth is None:\n",
    "            self.max_depth = X.shape[1]\n",
    "\n",
    "        # Если число образцов в выборке меньше минимального числа для разделения, \n",
    "        # либо достигнута максимальная глубина дерева, либо все метки y одинаковы, \n",
    "        # то задается метка для этого узла и завершается метод.\n",
    "        if X.shape[0] < self.min_samples_split or self.max_depth == 0 or len(np.unique(y)) == 1:\n",
    "            self.label = np.bincount(y).argmax()\n",
    "            return\n",
    "\n",
    "        best_feature = None\n",
    "        best_value = None\n",
    "        best_score = np.inf\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            for value in np.unique(X[:, feature]):\n",
    "                left_y = y[X[:, feature] < value]\n",
    "                right_y = y[X[:, feature] >= value]\n",
    "                if len(left_y) == 0 or len(right_y) == 0:\n",
    "                    continue\n",
    "                score = (len(left_y) * self.gini(left_y) + len(right_y) * self.gini(right_y)) / len(y)\n",
    "                if score < best_score:\n",
    "                    best_feature = feature\n",
    "                    best_value = value\n",
    "                    best_score = score\n",
    "\n",
    "        self.split_feature = best_feature\n",
    "        self.split_value = best_value\n",
    "\n",
    "        # Создание левого и правого потомков дерева с уменьшенной максимальной глубиной и минимальным \n",
    "        # количеством образцов для разделения, и рекурсивный вызов метода fit для каждого из них.\n",
    "        self.left_child = DecisionTree(max_depth=self.max_depth-1, min_samples_split=self.min_samples_split)\n",
    "        self.right_child = DecisionTree(max_depth=self.max_depth-1, min_samples_split=self.min_samples_split)\n",
    "        self.left_child.fit(X[X[:, best_feature] < best_value], y[X[:, best_feature] < best_value])\n",
    "        self.right_child.fit(X[X[:, best_feature] >= best_value], y[X[:, best_feature] >= best_value])\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Если задана метка для узла, то возвращается массив этой метки для всех примеров в X.\n",
    "        if self.label is not None:\n",
    "            return np.array([self.label] * X.shape[0])\n",
    "        else:\n",
    "            y = np.zeros(X.shape[0])\n",
    "            y[X[:, self.split_feature] < self.split_value] = self.left_child.predict(X[X[:, self.split_feature] < self.split_value])\n",
    "            y[X[:, self.split_feature] >= self.split_value] = self.right_child.predict(X[X[:, self.split_feature] >= self.split_value])\n",
    "            return y\n",
    "\n",
    "    def gini(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        p = counts / len(y)\n",
    "        return 1 - np.sum(p ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2, max_features=None):\n",
    "        self.n_estimators = n_estimators # количество деревьев\n",
    "        self.max_depth = max_depth # максимальная глубина каждого дерева\n",
    "        self.min_samples_split = min_samples_split # минимальное количество выборок для разделения \n",
    "        self.max_features = max_features # максимальное количество признаков для узлов деревьев\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.max_features is None:\n",
    "            self.max_features = int(np.sqrt(X.shape[1]))\n",
    "        for i in range(self.n_estimators):\n",
    "            sample_indices = np.random.choice(X.shape[0], X.shape[0])\n",
    "            feature_indices = np.random.choice(X.shape[1], self.max_features, replace=False)\n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "            tree.fit(X[sample_indices][:, feature_indices], y[sample_indices])\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for tree in self.trees:\n",
    "            y_pred += tree.predict(X[:, np.random.choice(X.shape[1], self.max_features, replace=False)]) / self.n_estimators\n",
    "            #print(y_pred)\n",
    "        if (y_pred <= 1).all():\n",
    "            return y_pred.round()\n",
    "        \n",
    "        y_pred = np.where(y_pred < 1, y_pred, y_pred.round())\n",
    "        return y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForest(n_estimators=1, max_depth=3, max_features=3)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 1, 1, 2, 1, 1, 2, 0, 2,\n",
       "       1, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = DecisionTree(max_depth=3, min_samples_split=2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2., 0., 0., 0., 0., 1., 2.,\n",
       "       1., 1., 2., 0., 2., 0., 2., 2., 2., 2., 2., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
